{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a2c4c9-de19-4882-b85f-0ffc63f04a56",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) & Machine Learning Algorithms (MLA)\n",
    "- Uncover patterns, trends, relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed831e19-fe37-4e20-831e-5931f756b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "# data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# multi-dimensional arrays and matrices\n",
    "# mathematical functions\n",
    "import numpy as np\n",
    "\n",
    "# parsing & processing Python Source Code\n",
    "# convert strings of Python code into executable code\n",
    "import ast # Abstract Syntax Trees (AST) module\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt # creating static, animated, and interactive visualizations\n",
    "import seaborn as sns # interface for drawing & statistical graphics\n",
    "import mplcursors # interactive data cursors\n",
    "import plotly.express as px\n",
    "\n",
    "# database adapter for Python\n",
    "import psycopg2 # allows interaction with PostgreSQL\n",
    "import pandas as pd\n",
    "\n",
    "# probability distributions and statistical functions\n",
    "from scipy.stats import norm \n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31078383-4a50-4c26-9056-9abf02e2df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(r'C:\\Users\\ashwi\\Documents\\Data Analytics\\Portfolio\\IGN VIdeo Game Rarings\\Python\\df_2.csv', index_col=False, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a61c0-14cc-447e-ab52-b0db4223b8e5",
   "metadata": {},
   "source": [
    "## regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3657a0-d20a-4787-b664-9acca36ca38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.892248908094975\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame df_2\n",
    "\n",
    "# Choose features and target variable\n",
    "X = df_2[['release_year', 'release_month', 'release_day']]  # Features\n",
    "y = df_2['score']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8edcdb-85cb-4880-a596-7dcfab54ea0f",
   "metadata": {},
   "source": [
    "## classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a460e02-ea6d-42b6-aed1-8b0c2d7fbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Amazing       0.98      1.00      0.99       343\n",
      "       Awful       0.74      0.57      0.64       132\n",
      "         Bad       0.79      0.83      0.81       242\n",
      "    Disaster       0.00      0.00      0.00         1\n",
      "        Good       1.00      1.00      1.00       959\n",
      "       Great       1.00      1.00      1.00       942\n",
      " Masterpiece       1.00      0.45      0.62        11\n",
      "    Mediocre       0.88      0.95      0.91       383\n",
      "        Okay       0.96      1.00      0.98       610\n",
      "     Painful       0.36      0.20      0.26        69\n",
      "  Unbearable       0.25      0.06      0.10        17\n",
      "\n",
      "    accuracy                           0.95      3709\n",
      "   macro avg       0.72      0.64      0.66      3709\n",
      "weighted avg       0.94      0.95      0.94      3709\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ashwi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ashwi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Preprocessing\n",
    "# Encode categorical variables using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_2[['platform', 'genre']])\n",
    "\n",
    "# Concatenate encoded features with numerical features\n",
    "X = pd.concat([df_encoded, df_2[['score', 'release_year', 'release_month', 'release_day']]], axis=1)\n",
    "y = df_2['score_phrase']\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Model Selection and Training\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 4. Model Evaluation\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42dad4b-91ec-49ec-a9f6-44aa91448a9b",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621efe2c-7825-49c7-8873-c9679c7c85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwi\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ashwi\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "df_numerical = df_2.drop(columns=['title', 'score_phrase', 'platform', 'genre'])  # Select numerical features\n",
    "scaler = StandardScaler()\n",
    "df_numerical_scaled = scaler.fit_transform(df_numerical)\n",
    "\n",
    "# Choosing the number of clusters (example with the elbow method)\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_numerical_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the elbow method\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()\n",
    "\n",
    "# Based on the elbow method, choose the appropriate number of clusters and train the model\n",
    "k = 3  # Example: Choose 3 clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(df_numerical_scaled)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df_2['cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualization (example with PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df_numerical_scaled)\n",
    "\n",
    "plt.scatter(df_pca[:, 0], df_pca[:, 1], c=kmeans.labels_, cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Clustering Visualization (PCA)')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc786f-4b09-4b0f-bbc1-fd9fcd33b1a8",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555a11b-e65f-4e87-91e7-4182f6d8bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical columns for PCA\n",
    "numerical_columns = ['score', 'release_year', 'release_month', 'release_day']\n",
    "X = df_2[numerical_columns]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)  # We choose 2 components for visualization\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a DataFrame with the PCA results\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Add the non-numerical columns back to the PCA DataFrame\n",
    "pca_df[['title', 'score_phrase', 'platform', 'genre']] = df_2[['title', 'score_phrase', 'platform', 'genre']]\n",
    "\n",
    "# Visualize the PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.5)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of Numerical Features')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
